<?xml version="1.0" encoding="UTF-8"?>
<project version="4">
  <component name="CopilotDiffPersistence">
    <option name="pendingDiffs">
      <map>
        <entry key="$PROJECT_DIR$/config.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/config.py" />
              <option name="originalContent" value="def models():&#10;    return {&#10;        'Erdos-Renyi': {'model_type': 'ER'},&#10;        'Barabasi-Albert': {'model_type': 'BA', 'm': 2},&#10;        'Watts-Strogatz': {'model_type': 'WS', 'k': 4, 'p': 0.1},&#10;        'Random Geometric': {'model_type': 'RGG', 'radius': 0.10},&#10;        'Hierarchical': {&#10;            'model_type': 'HIER',&#10;            'num_gateways': 20,&#10;            'sensors_per_gateway': 9&#10;        },&#10;    }&#10;&#10;STATIC_SIMULATION_CONFIG = {&#10;    'num_nodes': 200,&#10;    'num_runs_per_setting': 100,&#10;    'models': models(),&#10;    'strategies': ['random', 'targeted_degree', 'targeted_centrality'],&#10;    'results_filename': 'static_analysis_200n_100r.csv'&#10;}&#10;&#10;# Configuration for the dynamic experiment phase&#10;DYNAMIC_SIMULATION_CONFIG = {&#10;    'num_nodes': 200,&#10;    'num_runs_per_setting': 20,&#10;    'models': models(),&#10;    # Dynamic parameters&#10;    'steps': 1000,&#10;    'packet_rate': 2,&#10;    'node_failure_period': 100,&#10;    'node_recovery_steps': 20,&#10;    'base_energy_drain': 0.05,&#10;    'tx_energy_cost': 0.05,&#10;    'rx_energy_cost': 0.02,&#10;    'initial_energy': 100.0,&#10;    'link_flip_prob': 0.0,&#10;    'link_down_steps': 10,&#10;    'ttr_epsilon': 0.02,&#10;    # Outputs&#10;    'timeseries_filename': 'dynamic_timeseries.csv',&#10;    'summary_filename': 'dynamic_summary.csv',&#10;}&#10;" />
              <option name="updatedContent" value="def models():&#10;    return {&#10;        'Erdos-Renyi': {'model_type': 'ER'},&#10;        'Barabasi-Albert': {'model_type': 'BA', 'm': 2},&#10;        'Watts-Strogatz': {'model_type': 'WS', 'k': 4, 'p': 0.1},&#10;        'Random Geometric': {'model_type': 'RGG', 'radius': 0.10},&#10;        'Hierarchical': {&#10;            'model_type': 'HIER',&#10;            'num_gateways': 20,&#10;            'sensors_per_gateway': 9&#10;        },&#10;    }&#10;&#10;STATIC_SIMULATION_CONFIG = {&#10;    'num_nodes': 200,&#10;    'num_runs_per_setting': 100,&#10;    'models': models(),&#10;    'strategies': ['random', 'targeted_degree', 'targeted_centrality'],&#10;    'results_filename': 'static_analysis_200n_100r.csv'&#10;}&#10;&#10;# Configuration for the dynamic experiment phase&#10;DYNAMIC_SIMULATION_CONFIG = {&#10;    'num_nodes': 200,&#10;    'num_runs_per_setting': 20,&#10;    'models': models(),&#10;    # Dynamic parameters&#10;    'steps': 1000,&#10;    'packet_rate': 2,&#10;    'node_failure_period': 100,&#10;    'node_recovery_steps': 20,&#10;    'base_energy_drain': 0.05,&#10;    'tx_energy_cost': 0.05,&#10;    'rx_energy_cost': 0.02,&#10;    'initial_energy': 100.0,&#10;    'link_flip_prob': 0.0,&#10;    'link_down_steps': 10,&#10;    'ttr_epsilon': 0.02,&#10;    # Outputs&#10;    'timeseries_filename': 'dynamic_timeseries.csv',&#10;    'summary_filename': 'dynamic_summary.csv',&#10;}" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/plots/plot_results.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/plots/plot_results.py" />
              <option name="originalContent" value="import pandas as pd&#10;import matplotlib.pyplot as plt&#10;import os&#10;import argparse&#10;&#10;from config import STATIC_SIMULATION_CONFIG&#10;&#10;class ResultsPlotter:&#10;    &quot;&quot;&quot;Handles the visualization of simulation results from a DataFrame.&quot;&quot;&quot;&#10;&#10;    def __init__(self, results_df: pd.DataFrame, metric_to_plot: str):&#10;        self.df = results_df&#10;        self.metric = metric_to_plot&#10;        self.summary = results_df.groupby(&#10;            ['model_name', 'attack_strategy', 'nodes_removed_fraction']&#10;        )[self.metric].mean().reset_index()&#10;&#10;    def plot_comparison(self, save_plot=False, output_filename=&quot;resilience_comparison.png&quot;):&#10;        &quot;&quot;&quot;Creates a multi-plot figure for comparison.&quot;&quot;&quot;&#10;        models = self.summary['model_name'].unique()&#10;        n_models = len(models)&#10;&#10;        plt.style.use('seaborn-v0_8-whitegrid')&#10;        fig, axes = plt.subplots(1, n_models, figsize=(7 * n_models, 6), sharey=False)&#10;        if n_models == 1: axes = [axes]&#10;&#10;        line_styles = {'random': '--', 'targeted_degree': '-', 'targeted_centrality': '-.'}&#10;&#10;        for ax, model_name in zip(axes, models):&#10;            model_data = self.summary[self.summary['model_name'] == model_name]&#10;            for strategy in model_data['attack_strategy'].unique():&#10;                strategy_data = model_data[model_data['attack_strategy'] == strategy]&#10;&#10;                ax.plot(&#10;                    strategy_data['nodes_removed_fraction'],&#10;                    strategy_data[self.metric],&#10;                    label=strategy.replace(&quot;_&quot;, &quot; &quot;).title(),&#10;                    linestyle=line_styles.get(strategy, ':')&#10;                )&#10;&#10;            ax.set_title(f&quot;Resilience of {model_name} Network&quot;, fontsize=14)&#10;            ax.set_xlabel(&quot;Fraction of Nodes Removed&quot;)&#10;            ax.legend()&#10;&#10;        y_label = self.metric.replace(&quot;_&quot;, &quot; &quot;).title()&#10;        if self.metric == 'lcc':&#10;            y_label = &quot;Fractional Size of LCC&quot; # Make it more descriptive&#10;&#10;        axes[0].set_ylabel(y_label)&#10;        fig.suptitle(f&quot;Network Robustness Comparison: {y_label}&quot;, fontsize=16)&#10;        fig.tight_layout(rect=(0, 0.03, 1, 0.95))&#10;&#10;        if save_plot:&#10;            output_dir = &quot;plots&quot;&#10;            if not os.path.exists(output_dir):&#10;                os.makedirs(output_dir)&#10;&#10;            filepath = os.path.join(output_dir, output_filename)&#10;            plt.savefig(filepath, dpi=300, bbox_inches='tight')&#10;            print(f&quot;Plot successfully saved to '{filepath}'&quot;)&#10;            plt.close()&#10;        else:&#10;            plt.show()&#10;&#10;def main():&#10;    &quot;&quot;&quot;Main function to load results and generate plots.&quot;&quot;&quot;&#10;    parser = argparse.ArgumentParser(description=&quot;Plot network resilience simulation results.&quot;)&#10;    parser.add_argument(&#10;        '--save',&#10;        action='store_true',&#10;        help=&quot;Save the plot to a file instead of displaying it.&quot;&#10;    )&#10;    parser.add_argument(&#10;        '-o', '--output',&#10;        type=str,&#10;        default=&quot;resilience_comparison.png&quot;,&#10;        help=&quot;Name of the output file if --save is used.&quot;&#10;    )&#10;    parser.add_argument(&#10;        '-m', '--metric',&#10;        type=str,&#10;        default=&quot;lcc&quot;, # Default to plotting LCC&#10;        help=&quot;The metric to plot from the results file (one of: 'lcc', 'algebraic_connectivity', 'smoothness').&quot;&#10;    )&#10;    args = parser.parse_args()&#10;&#10;    results_file = STATIC_SIMULATION_CONFIG['results_filename']&#10;&#10;    if not os.path.exists(results_file):&#10;        print(f&quot;Error: Results file '{results_file}' not found.&quot;)&#10;        print(&quot;Please run the simulation script first.&quot;)&#10;        return&#10;&#10;    print(f&quot;Loading results from '{results_file}'...&quot;)&#10;    results_dataframe = pd.read_csv(results_file)&#10;&#10;    plotter = ResultsPlotter(results_dataframe, metric_to_plot=args.metric)&#10;    print(f&quot;Generating plots for metric: '{args.metric}'...&quot;)&#10;&#10;    plotter.plot_comparison(save_plot=args.save, output_filename=args.output)&#10;&#10;if __name__ == '__main__':&#10;    main()&#10;" />
              <option name="updatedContent" value="import pandas as pd&#10;import matplotlib.pyplot as plt&#10;import os&#10;import argparse&#10;&#10;from config import STATIC_SIMULATION_CONFIG&#10;&#10;class ResultsPlotter:&#10;    &quot;&quot;&quot;Handles the visualization of simulation results from a DataFrame.&quot;&quot;&quot;&#10;&#10;    def __init__(self, results_df: pd.DataFrame, metric_to_plot: str):&#10;        self.df = results_df&#10;        self.metric = metric_to_plot&#10;        self.summary = results_df.groupby(&#10;            ['model_name', 'attack_strategy', 'nodes_removed_fraction']&#10;        )[self.metric].mean().reset_index()&#10;&#10;    def plot_comparison(self, save_plot=False, output_filename=&quot;resilience_comparison.png&quot;):&#10;        &quot;&quot;&quot;Creates a multi-plot figure for comparison.&quot;&quot;&quot;&#10;        models = self.summary['model_name'].unique()&#10;        n_models = len(models)&#10;&#10;        plt.style.use('seaborn-v0_8-whitegrid')&#10;        fig, axes = plt.subplots(1, n_models, figsize=(7 * n_models, 6), sharey=False)&#10;        if n_models == 1: axes = [axes]&#10;&#10;        line_styles = {'random': '--', 'targeted_degree': '-', 'targeted_centrality': '-.'}&#10;&#10;        for ax, model_name in zip(axes, models):&#10;            model_data = self.summary[self.summary['model_name'] == model_name]&#10;            for strategy in model_data['attack_strategy'].unique():&#10;                strategy_data = model_data[model_data['attack_strategy'] == strategy]&#10;&#10;                ax.plot(&#10;                    strategy_data['nodes_removed_fraction'],&#10;                    strategy_data[self.metric],&#10;                    label=strategy.replace(&quot;_&quot;, &quot; &quot;).title(),&#10;                    linestyle=line_styles.get(strategy, ':')&#10;                )&#10;&#10;            ax.set_title(f&quot;Resilience of {model_name} Network&quot;, fontsize=14)&#10;            ax.set_xlabel(&quot;Fraction of Nodes Removed&quot;)&#10;            ax.legend()&#10;&#10;        y_label = self.metric.replace(&quot;_&quot;, &quot; &quot;).title()&#10;        if self.metric == 'lcc':&#10;            y_label = &quot;Fractional Size of LCC&quot; # Make it more descriptive&#10;&#10;        axes[0].set_ylabel(y_label)&#10;        fig.suptitle(f&quot;Network Robustness Comparison: {y_label}&quot;, fontsize=16)&#10;        fig.tight_layout(rect=(0, 0.03, 1, 0.95))&#10;&#10;        if save_plot:&#10;            output_dir = &quot;plots&quot;&#10;            if not os.path.exists(output_dir):&#10;                os.makedirs(output_dir)&#10;&#10;            filepath = os.path.join(output_dir, output_filename)&#10;            plt.savefig(filepath, dpi=300, bbox_inches='tight')&#10;            print(f&quot;Plot successfully saved to '{filepath}'&quot;)&#10;            plt.close()&#10;        else:&#10;            plt.show()&#10;&#10;def main():&#10;    &quot;&quot;&quot;Main function to load results and generate plots.&quot;&quot;&quot;&#10;    parser = argparse.ArgumentParser(description=&quot;Plot network resilience simulation results.&quot;)&#10;    parser.add_argument(&#10;        '--save',&#10;        action='store_true',&#10;        help=&quot;Save the plot to a file instead of displaying it.&quot;&#10;    )&#10;    parser.add_argument(&#10;        '-o', '--output',&#10;        type=str,&#10;        default=&quot;resilience_comparison.png&quot;,&#10;        help=&quot;Name of the output file if --save is used.&quot;&#10;    )&#10;    parser.add_argument(&#10;        '-m', '--metric',&#10;        type=str,&#10;        default=&quot;lcc&quot;, # Default to plotting LCC&#10;        help=&quot;The metric to plot from the results file (one of: 'lcc', 'algebraic_connectivity', 'smoothness').&quot;&#10;    )&#10;    args = parser.parse_args()&#10;&#10;    results_file = STATIC_SIMULATION_CONFIG['results_filename']&#10;&#10;    if not os.path.exists(results_file):&#10;        print(f&quot;Error: Results file '{results_file}' not found.&quot;)&#10;        print(&quot;Please run the simulation script first.&quot;)&#10;        return&#10;&#10;    print(f&quot;Loading results from '{results_file}'...&quot;)&#10;    results_dataframe = pd.read_csv(results_file)&#10;&#10;    plotter = ResultsPlotter(results_dataframe, metric_to_plot=args.metric)&#10;    print(f&quot;Generating plots for metric: '{args.metric}'...&quot;)&#10;&#10;    plotter.plot_comparison(save_plot=args.save, output_filename=args.output)&#10;&#10;if __name__ == '__main__':&#10;    main()" />
            </PendingDiffInfo>
          </value>
        </entry>
      </map>
    </option>
  </component>
</project>